{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba429c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 26324 translation pairs from npd.no.en-nb.tmx\n",
      "\n",
      "First 3 examples:\n",
      "--------------------------------------------------------------------------------\n",
      "1. Norwegian: Brønn 16/1-23 S skal borast frå boreinnretninga Rowan Viking i posisjon 58°49’47,04’’ nord 02°16’56,00’’ aust i utvinningsløyve 338.\n",
      "   English: Well 16/1-23 S will be drilled from the Rowan Viking drilling facility at position 58°49’47.04’’ north 02°16’56.00’’ east in production licence 338.\n",
      "\n",
      "2. Norwegian: Boreprogrammet for brønn 16/1-23 S gjeld boring av avgrensingsbrønn i utvinningsløyve 338.\n",
      "   English: The drilling programme for well 16/1-23 S relates to the drilling of an appraisal well in production licence 338.\n",
      "\n",
      "3. Norwegian: Lundin er operatør med 50 prosent del.\n",
      "   English: Lundin is the operator with a 50 per cent ownership interest.\n",
      "\n",
      "================================================================================\n",
      "Saved: npd_no_en_train.jsonl (26324 pairs)\n",
      "\n",
      "Conversion complete!\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "def parse_tmx_no_to_en(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    root = ET.fromstring(content)\n",
    "    pairs = []\n",
    "    \n",
    "    for tu in root.findall('.//tu'):\n",
    "        tuvs = tu.findall('tuv')\n",
    "        if len(tuvs) >= 2:\n",
    "            en_text = None\n",
    "            nb_text = None\n",
    "            \n",
    "            for tuv in tuvs:\n",
    "                lang = tuv.get('{http://www.w3.org/XML/1998/namespace}lang')\n",
    "                seg = tuv.find('seg')\n",
    "                text = seg.text.strip() if seg is not None and seg.text else \"\"\n",
    "                \n",
    "                if lang == 'en' and text:\n",
    "                    en_text = text\n",
    "                elif lang == 'nb' and text:\n",
    "                    nb_text = text\n",
    "            \n",
    "            if nb_text and en_text:\n",
    "                pairs.append((nb_text, en_text))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def save_parallel_files(pairs, output_prefix):\n",
    "    with open(f\"{output_prefix}.no\", 'w', encoding='utf-8') as no_file, \\\n",
    "         open(f\"{output_prefix}.en\", 'w', encoding='utf-8') as en_file:\n",
    "        for no_text, en_text in pairs:\n",
    "            no_file.write(no_text + '\\n')\n",
    "            en_file.write(en_text + '\\n')\n",
    "    \n",
    "    print(f\"Saved: {output_prefix}.no ({len(pairs)} lines)\")\n",
    "    print(f\"Saved: {output_prefix}.en ({len(pairs)} lines)\")\n",
    "\n",
    "def save_tsv(pairs, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"norwegian\\tenglish\\n\")\n",
    "        for no_text, en_text in pairs:\n",
    "            f.write(f\"{no_text}\\t{en_text}\\n\")\n",
    "    print(f\"Saved: {output_file} ({len(pairs)} pairs)\")\n",
    "\n",
    "def save_jsonl(pairs, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for no_text, en_text in pairs:\n",
    "            json.dump({\n",
    "                \"source\": no_text,\n",
    "                \"target\": en_text,\n",
    "                \"source_lang\": \"nb\",\n",
    "                \"target_lang\": \"en\"\n",
    "            }, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "    print(f\"Saved: {output_file} ({len(pairs)} pairs)\")\n",
    "\n",
    "def save_huggingface_format(pairs, output_file):\n",
    "    data = {\n",
    "        \"translation\": [\n",
    "            {\"nb\": no_text, \"en\": en_text} \n",
    "            for no_text, en_text in pairs\n",
    "        ]\n",
    "    }\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Saved: {output_file} ({len(pairs)} pairs)\")\n",
    "\n",
    "def save_fairseq_format(pairs, output_prefix):\n",
    "    save_parallel_files(pairs, output_prefix)\n",
    "    print(f\"Fairseq format saved and ready for fairseq-preprocess\")\n",
    "\n",
    "def convert_tmx_no_to_en(input_file, format_type=\"jsonl\", output_name=None):\n",
    "    try:\n",
    "        pairs = parse_tmx_no_to_en(input_file)\n",
    "        print(f\"\\nExtracted {len(pairs)} translation pairs from {input_file}\\n\")\n",
    "        \n",
    "        print(\"First 3 examples:\")\n",
    "        print(\"-\" * 80)\n",
    "        for i, (no_text, en_text) in enumerate(pairs[:3], 1):\n",
    "            print(f\"{i}. Norwegian: {no_text}\")\n",
    "            print(f\"   English: {en_text}\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing TMX file: {e}\")\n",
    "        return\n",
    "    \n",
    "    if not output_name:\n",
    "        output_name = input_file.replace('.tmx', '').replace('.', '_')\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    try:\n",
    "        if format_type == \"parallel\":\n",
    "            save_parallel_files(pairs, output_name)\n",
    "        elif format_type == \"tsv\":\n",
    "            save_tsv(pairs, f\"{output_name}.tsv\")\n",
    "        elif format_type == \"jsonl\":\n",
    "            save_jsonl(pairs, f\"{output_name}.jsonl\")\n",
    "        elif format_type == \"huggingface\":\n",
    "            save_huggingface_format(pairs, f\"{output_name}_hf.json\")\n",
    "        elif format_type == \"fairseq\":\n",
    "            save_fairseq_format(pairs, output_name)\n",
    "        else:\n",
    "            print(f\"Unknown format: {format_type}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nConversion complete!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    convert_tmx_no_to_en(\"npd.no.en-nb.tmx\", \"jsonl\", \"npd_no_en_train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b42dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
