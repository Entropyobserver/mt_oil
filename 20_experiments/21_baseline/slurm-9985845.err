
[notice] A new release of pip is available: 25.2 -> 25.3
[notice] To update, run: pip install --upgrade pip
/proj/uppmax2025-3-5/private/yaxj1/conda_envs/mt/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/proj/uppmax2025-3-5/private/yaxj1/conda_envs/mt/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/proj/uppmax2025-3-5/private/yaxj1/conda_envs/mt/lib/python3.9/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|██████████| 100/100 [00:00<00:00, 717.96 examples/s]                                                              Map:   0%|          | 0/1702 [00:00<?, ? examples/s]Map:  59%|█████▉    | 1000/1702 [00:00<00:00, 4388.33 examples/s]Map: 100%|██████████| 1702/1702 [00:00<00:00, 4571.88 examples/s]                                                                 /proj/uppmax2025-3-5/private/yaxj1/conda_envs/mt/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/18 [00:00<?, ?it/s]You're using a NllbTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  6%|▌         | 1/18 [00:09<02:48,  9.93s/it] 11%|█         | 2/18 [00:12<01:28,  5.52s/it] 17%|█▋        | 3/18 [00:14<01:01,  4.10s/it] 22%|██▏       | 4/18 [00:17<00:48,  3.45s/it] 28%|██▊       | 5/18 [00:19<00:39,  3.07s/it] 33%|███▎      | 6/18 [00:21<00:33,  2.83s/it] 39%|███▉      | 7/18 [00:24<00:29,  2.67s/it] 44%|████▍     | 8/18 [00:26<00:25,  2.57s/it] 50%|█████     | 9/18 [00:29<00:22,  2.50s/it] 56%|█████▌    | 10/18 [00:31<00:19,  2.45s/it] 61%|██████    | 11/18 [00:33<00:16,  2.41s/it] 67%|██████▋   | 12/18 [00:36<00:14,  2.39s/it] 72%|███████▏  | 13/18 [00:38<00:11,  2.37s/it] 78%|███████▊  | 14/18 [00:40<00:09,  2.36s/it] 83%|████████▎ | 15/18 [00:43<00:07,  2.35s/it] 89%|████████▉ | 16/18 [00:45<00:04,  2.34s/it] 94%|█████████▍| 17/18 [00:47<00:02,  2.34s/it]100%|██████████| 18/18 [00:49<00:00,  2.33s/it]                                               100%|██████████| 18/18 [00:49<00:00,  2.33s/it]100%|██████████| 18/18 [00:49<00:00,  2.78s/it]
  0%|          | 0/426 [00:00<?, ?it/s]  0%|          | 2/426 [00:01<06:49,  1.04it/s]  1%|          | 3/426 [00:03<08:21,  1.19s/it]  1%|          | 4/426 [00:04<08:29,  1.21s/it]  1%|          | 5/426 [00:07<11:53,  1.69s/it]  1%|▏         | 6/426 [00:09<12:12,  1.74s/it]  2%|▏         | 7/426 [00:10<11:43,  1.68s/it]  2%|▏         | 8/426 [00:13<14:15,  2.05s/it]  2%|▏         | 9/426 [00:15<14:05,  2.03s/it]  2%|▏         | 10/426 [00:17<13:20,  1.92s/it]  3%|▎         | 11/426 [00:19<14:02,  2.03s/it]  3%|▎         | 12/426 [00:23<17:29,  2.53s/it]  3%|▎         | 13/426 [00:24<14:58,  2.18s/it]  3%|▎         | 14/426 [00:27<15:43,  2.29s/it]  4%|▎         | 15/426 [00:29<15:27,  2.26s/it]  4%|▍         | 16/426 [00:31<15:21,  2.25s/it]  4%|▍         | 17/426 [00:34<17:17,  2.54s/it]slurmstepd: error: *** JOB 9985845 ON s171 CANCELLED AT 2025-12-04T10:39:05 ***
  4%|▍         | 18/426 [00:36<16:48,  2.47s/it]